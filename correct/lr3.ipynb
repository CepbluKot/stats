{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "data = None\n",
    "with open('Москва_2021.txt') as file:\n",
    "    data = [int(line.rstrip()) for line in file]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mathematical_expectation(data: list):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "        if val not in num_of_occurrences:\n",
    "            num_of_occurrences[val] = 1\n",
    "        else:\n",
    "            num_of_occurrences[val] += 1 \n",
    "\n",
    "    mat_exp = 0\n",
    "\n",
    "    for val in num_of_occurrences:\n",
    "        mat_exp += (num_of_occurrences[val] / len(data)) * val\n",
    "\n",
    "    return mat_exp\n",
    "\n",
    "\n",
    "def count_dispersion(data: list):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "        if val not in num_of_occurrences:\n",
    "            num_of_occurrences[val] = 1\n",
    "        else:\n",
    "            num_of_occurrences[val] += 1 \n",
    "\n",
    "    mat_exp = count_mathematical_expectation(data)\n",
    "    dispersion = 0\n",
    "\n",
    "    for val in num_of_occurrences:\n",
    "        dispersion += (val - mat_exp) ** 2 * (num_of_occurrences[val] / len(data))\n",
    "    \n",
    "    return dispersion\n",
    "\n",
    "\n",
    "def count_sko(data):\n",
    "    return count_dispersion(data) ** 0.5\n",
    "\n",
    "\n",
    "def count_avg(data: list):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "\n",
    "def count_avg(data: list):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def count_mathematical_expectation(data: list):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "        if val not in num_of_occurrences:\n",
    "            num_of_occurrences[val] = 1\n",
    "        else:\n",
    "            num_of_occurrences[val] += 1 \n",
    "\n",
    "    mat_exp = 0\n",
    "\n",
    "    for val in num_of_occurrences:\n",
    "        mat_exp += (num_of_occurrences[val] / len(data)) * val\n",
    "\n",
    "    return mat_exp\n",
    "\n",
    "\n",
    "def count_dispersion(data: list):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "        if val not in num_of_occurrences:\n",
    "            num_of_occurrences[val] = 1\n",
    "        else:\n",
    "            num_of_occurrences[val] += 1 \n",
    "\n",
    "    mat_exp = count_mathematical_expectation(data)\n",
    "    dispersion = 0\n",
    "\n",
    "    for val in num_of_occurrences:\n",
    "        dispersion += (val - mat_exp) ** 2 * (num_of_occurrences[val] / len(data))\n",
    "    \n",
    "    return dispersion\n",
    "\n",
    "\n",
    "def count_sko(data):\n",
    "    return count_dispersion(data) ** 0.5\n",
    "\n",
    "\n",
    "def count_var_coef(data):\n",
    "    return count_sko(data) / count_mathematical_expectation(data)\n",
    "\n",
    "def count_moda(data):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "        if val not in num_of_occurrences:\n",
    "            num_of_occurrences[val] = 1\n",
    "        else:\n",
    "            num_of_occurrences[val] += 1 \n",
    "    \n",
    "    max_val = max(num_of_occurrences, key=num_of_occurrences.get)\n",
    "    max_val_freq = num_of_occurrences[max_val] / len(data)\n",
    "\n",
    "    return [max_val, num_of_occurrences[max_val], len(data)]\n",
    "\n",
    "def count_razmax(data):\n",
    "    return max(data) - min(data)\n",
    "\n",
    "def find_second_max_and_min(data):\n",
    "\n",
    "    sorted_data = sorted(set(data))\n",
    "    \n",
    "    return sorted_data[1], sorted_data[-2]\n",
    "\n",
    "def find_k_momentum(data: list, k: int):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "        if val not in num_of_occurrences:\n",
    "            num_of_occurrences[val] = 1\n",
    "        else:\n",
    "            num_of_occurrences[val] += 1 \n",
    "    \n",
    "    mat_exp = count_mathematical_expectation(data)\n",
    "\n",
    "    momentum = 0\n",
    "\n",
    "    for val in num_of_occurrences:\n",
    "        momentum += (val - mat_exp) ** k * (num_of_occurrences[val] / len(data))\n",
    "    \n",
    "    return momentum\n",
    "\n",
    "def count_asymmetry(data):\n",
    "    return find_k_momentum(data, 3) / (count_sko(data) ** 3)\n",
    "\n",
    "def count_excess(data):\n",
    "    return find_k_momentum(data, 4) / (count_sko(data) ** 4) - 3\n",
    "\n",
    "\n",
    "def count_median(data):\n",
    "    if len(data) % 2 == 1:\n",
    "        m = (len(data)-1) // 2\n",
    "        return sorted(data)[m+1]\n",
    "    else:\n",
    "        m = len(data) // 2\n",
    "        return (sorted(data)[m] + sorted(data)[m+1])/2\n",
    "\n",
    "\n",
    "def count_frequencies(data):\n",
    "    num_of_occurrences = {}\n",
    "\n",
    "    for val in data:\n",
    "            if val not in num_of_occurrences:\n",
    "                num_of_occurrences[val] = 1\n",
    "            else:\n",
    "                num_of_occurrences[val] += 1 \n",
    "\n",
    "    return num_of_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. По критерию Пирсона при уровне значимости α = 0,05 проверить\n",
    "нулевую гипотезу о нормальном распределении:\n",
    "\n",
    "а) случайной величины «возраст». Для этого разбить массив исходных\n",
    "данных на 7 групп с равными интервалами (концы интервала –\n",
    "целые).\n",
    "\n",
    "б) случайной величины «средний возраст», используя выборку\n",
    "средних, полученную в лабораторной работе №2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_to_same_intervals(data: list, n_parts: int): \n",
    "    data = sorted(data)\n",
    "    \n",
    "    curr_interval = 1\n",
    "    \n",
    "    interval_is_ok = True\n",
    "    \n",
    "    while interval_is_ok:        \n",
    "        curr_n_parts = 0\n",
    "        begin_id = 0\n",
    "        end_id = 1\n",
    "\n",
    "        # all_intervals = []\n",
    "        while end_id < len(data) and curr_n_parts < n_parts:\n",
    "            while end_id < len(data) and data[end_id] - data[begin_id] <= curr_interval:\n",
    "                end_id += 1\n",
    "\n",
    "            # all_intervals.append(data[begin_id:end_id])\n",
    "            begin_id = end_id - 1\n",
    "            curr_n_parts += 1\n",
    "\n",
    "        if end_id >= len(data) and curr_n_parts < n_parts:\n",
    "            interval_is_ok = False\n",
    "        \n",
    "        else:\n",
    "            curr_interval += 1\n",
    "\n",
    "\n",
    "    final_interval_size = curr_interval - 1\n",
    "\n",
    "    all_intervals = []\n",
    "    while  curr_n_parts <= n_parts:\n",
    "        while data[end_id] - data[begin_id] <= final_interval_size:\n",
    "            end_id += 1\n",
    "\n",
    "        all_intervals.append(data[begin_id:end_id])\n",
    "        begin_id = end_id - 1\n",
    "        curr_n_parts += 1\n",
    "\n",
    "    return all_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_func(x):\n",
    "    return 1 / ((2 * math.pi) ** 0.5) * math.e ** ( - (x) ** 2 / (2) )\n",
    "\n",
    "\n",
    "def count_theoretical_frequencies(data: list, empyric_freqs: dict=None):\n",
    "    avg = count_avg(data)\n",
    "    # disp = count_dispersion(data)\n",
    "    sko = count_sko(data)\n",
    "    n = len(data)\n",
    "    h = 1\n",
    "\n",
    "    freqs = {}\n",
    "\n",
    "    # empyric_freqs_sum = 0\n",
    "    # for freqa in empyric_freqs:\n",
    "    #     empyric_freqs_sum += empyric_freqs[freqa]\n",
    "\n",
    "    for val in data:\n",
    "        freqs[val] = h * n / sko * gauss_func((val - avg)/sko)\n",
    "\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[150], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# уровень значимости\u001b[39;00m\n\u001b[1;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[0;32m----> 5\u001b[0m all_samples \u001b[38;5;241m=\u001b[39m \u001b[43mdivide_to_same_intervals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_samples)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# k = len(sample) - 2 - 1 # это колво степеней свободы\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# for sample in all_samples:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     # print(pirson) \u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     print(min(sample))\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[148], line 33\u001b[0m, in \u001b[0;36mdivide_to_same_intervals\u001b[0;34m(data, n_parts)\u001b[0m\n\u001b[1;32m     31\u001b[0m all_intervals \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m  curr_n_parts \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_parts:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mend_id\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m data[begin_id] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m final_interval_size:\n\u001b[1;32m     34\u001b[0m         end_id \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     36\u001b[0m     all_intervals\u001b[38;5;241m.\u001b[39mappend(data[begin_id:end_id])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# уровень значимости\n",
    "a = 0.05\n",
    "\n",
    "\n",
    "all_samples = divide_to_same_intervals(data, 7)\n",
    "print(all_samples)\n",
    "# k = len(sample) - 2 - 1 # это колво степеней свободы\n",
    "\n",
    "# for sample in all_samples:\n",
    "#     # #  Вычислим теоретические частоты\n",
    "#     # theoretical_freqs = count_theoretical_frequencies(sample )\n",
    "#     # sample_freqs = count_frequencies(sample )\n",
    "#     # # Найдём критическое значение  критерия согласия Пирсона\n",
    "\n",
    "\n",
    "#     # pirson = 0\n",
    "#     # for val in theoretical_freqs:\n",
    "#     #     pirson += ((sample_freqs[val] - theoretical_freqs[val]) ** 2) / theoretical_freqs[val]\n",
    "\n",
    "#     # print(pirson) \n",
    "#     print(min(sample))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
